{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb39d7a",
   "metadata": {},
   "source": [
    "### Задание 1.\n",
    "Обязательная часть\n",
    "Будем парсить страницу со свежеми новостям на habr.com/ru/all/.\n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
    "\n",
    "KEYWORDS = ['python', 'парсинг']\n",
    "\n",
    "Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы).\n",
    "\n",
    "В итоге должен формироваться датафрейм вида: <дата> - <заголовок> - <ссылка>\n",
    "\n",
    "Дополнительная часть (необязательная)\n",
    "Улучшить скрипт так, чтобы он анализировал не только preview-информацию статьи, но и весь текст статьи целиком.\n",
    "\n",
    "Для этого потребуется получать страницы статей и искать по тексту внутри этой страницы.\n",
    "\n",
    "Итоговый датафрейм формировать со столбцами: <дата> - <заголовок> - <ссылка> - <текст_статьи>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1bc2b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d1255e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_url = 'https://habr.com'                                                           # голова адреса страницы\n",
    "url = head_url + '/ru/all/'                                                             # адрес страницы\n",
    "keywords = ['python', 'парсинг']                                                        # список слов для поиска\n",
    "headers = {'User-Agent': \n",
    "           'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.70'\n",
    "          }\n",
    "keywords_search = '|'.join(keywords).lower()                                            # строка поиска в формате RegExp\n",
    "params = {}                                                                             # словарь параметров\n",
    "df_result = pd.DataFrame()                                                              # DataFrame результатов поиска\n",
    "\n",
    "def find_item(head_url, post):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.70'}\n",
    "    header = post.find('a', class_='tm-article-snippet__title-link')                    # делим пост на заголовок\n",
    "    post_header = header.text\n",
    "    post_review = post.find('div', class_='article-formatted-body').text                #                        и обзор\n",
    "    post_link   = head_url + header.attrs.get('href')                                   # из заголовка получаем ссылку  \n",
    "    req = requests.get(post_link, headers=headers)                                      # по ссылке запрашиваем содержимое\n",
    "    if req.ok:                                                                          # если содержимое получено\n",
    "        soup =  BeautifulSoup(req.text, 'html.parser')                                  \n",
    "        post_body = soup.find('div', class_='tm-article-body').text                     # то достаем из него текст статьи\n",
    "    else:\n",
    "        post_body =''\n",
    "    if (re.search(fr\"{keywords_search}\",                                                # если находим ключевые слова\n",
    "                  post_header                                                           # в заголовке\n",
    "                  + post_review                                                         # обзоре\n",
    "                  + post_body)):                                                        # или самом тексте статьи,\n",
    "        post_date = (post.find('span', class_='tm-article-snippet__datetime-published') # то получаем дату из поста    \n",
    "                     .time                                                              \n",
    "                     .attrs                                                             \n",
    "                     .get('datetime'))                                                                    \n",
    "        return {'Дата': post_date,                                                      # и возвращаем результат в виде словаря\n",
    "                'Заголовок': str(post_header).strip(), \n",
    "                'Ссылка': post_link, \n",
    "                'Текст статьи': str(post_body).strip()}\n",
    "    else:                                                                               # если совпадений не найдено,\n",
    "        return False                                                                    # то возвращаем False\n",
    "    \n",
    "req = requests.get(url, headers=headers)                                                # читаем содержимое с заданной страницы\n",
    "soup = BeautifulSoup(req.text, 'html.parser') \n",
    "page_count = int(soup.find_all('a', class_=\"tm-pagination__page\")[-1].text.strip())     # ищем число страниц\n",
    "for page in range(1, page_count + 1):                                                   # проходим по каждой странице \n",
    "    params['page'] = page                                                               # в параметры передаем номер текущей страницы\n",
    "    req = requests.get(url, params, headers=headers)                                    # запрашиваем содержимое текущей страницы\n",
    "    if req.ok:                                                                          # если результат запроса удачный\n",
    "        soup = BeautifulSoup(req.text, 'html.parser')                                   # читаем текст в суп\n",
    "        posts = soup.find_all('div', class_='tm-article-snippet')                       # разбиваем на посты\n",
    "        for post in posts:                                                              # проходим по каждому посту\n",
    "            item = find_item(head_url, post)                                            # передаем шапку адреса и пост, получаем словарь или False\n",
    "            time.sleep(0.3)\n",
    "            if item:                                                                    # если вернулся словарь, то добавляем в DF\n",
    "                df_result = df_result.append(item, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3264d289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Дата</th>\n",
       "      <th>Заголовок</th>\n",
       "      <th>Ссылка</th>\n",
       "      <th>Текст статьи</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-21T16:52:54.000Z</td>\n",
       "      <td>@teqfw/http2</td>\n",
       "      <td>https://habr.com/ru/post/568578/</td>\n",
       "      <td>Я очень долго не воспринимал JavaScript, как я...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-21T15:54:01.000Z</td>\n",
       "      <td>Не суйте свой Pydantic в мое Django</td>\n",
       "      <td>https://habr.com/ru/post/568556/</td>\n",
       "      <td>Было замечательное теплое австрийское утро, и ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-21T16:52:54.000Z</td>\n",
       "      <td>@teqfw/http2</td>\n",
       "      <td>https://habr.com/ru/post/568578/</td>\n",
       "      <td>Я очень долго не воспринимал JavaScript, как я...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-21T15:54:01.000Z</td>\n",
       "      <td>Не суйте свой Pydantic в мое Django</td>\n",
       "      <td>https://habr.com/ru/post/568556/</td>\n",
       "      <td>Было замечательное теплое австрийское утро, и ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-21T16:52:54.000Z</td>\n",
       "      <td>@teqfw/http2</td>\n",
       "      <td>https://habr.com/ru/post/568578/</td>\n",
       "      <td>Я очень долго не воспринимал JavaScript, как я...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2021-07-21T15:54:01.000Z</td>\n",
       "      <td>Не суйте свой Pydantic в мое Django</td>\n",
       "      <td>https://habr.com/ru/post/568556/</td>\n",
       "      <td>Было замечательное теплое австрийское утро, и ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2021-07-21T16:52:54.000Z</td>\n",
       "      <td>@teqfw/http2</td>\n",
       "      <td>https://habr.com/ru/post/568578/</td>\n",
       "      <td>Я очень долго не воспринимал JavaScript, как я...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2021-07-21T15:54:01.000Z</td>\n",
       "      <td>Не суйте свой Pydantic в мое Django</td>\n",
       "      <td>https://habr.com/ru/post/568556/</td>\n",
       "      <td>Было замечательное теплое австрийское утро, и ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2021-07-21T16:52:54.000Z</td>\n",
       "      <td>@teqfw/http2</td>\n",
       "      <td>https://habr.com/ru/post/568578/</td>\n",
       "      <td>Я очень долго не воспринимал JavaScript, как я...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2021-07-21T15:54:01.000Z</td>\n",
       "      <td>Не суйте свой Pydantic в мое Django</td>\n",
       "      <td>https://habr.com/ru/post/568556/</td>\n",
       "      <td>Было замечательное теплое австрийское утро, и ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Дата                            Заголовок  \\\n",
       "0   2021-07-21T16:52:54.000Z                         @teqfw/http2   \n",
       "1   2021-07-21T15:54:01.000Z  Не суйте свой Pydantic в мое Django   \n",
       "2   2021-07-21T16:52:54.000Z                         @teqfw/http2   \n",
       "3   2021-07-21T15:54:01.000Z  Не суйте свой Pydantic в мое Django   \n",
       "4   2021-07-21T16:52:54.000Z                         @teqfw/http2   \n",
       "..                       ...                                  ...   \n",
       "95  2021-07-21T15:54:01.000Z  Не суйте свой Pydantic в мое Django   \n",
       "96  2021-07-21T16:52:54.000Z                         @teqfw/http2   \n",
       "97  2021-07-21T15:54:01.000Z  Не суйте свой Pydantic в мое Django   \n",
       "98  2021-07-21T16:52:54.000Z                         @teqfw/http2   \n",
       "99  2021-07-21T15:54:01.000Z  Не суйте свой Pydantic в мое Django   \n",
       "\n",
       "                              Ссылка  \\\n",
       "0   https://habr.com/ru/post/568578/   \n",
       "1   https://habr.com/ru/post/568556/   \n",
       "2   https://habr.com/ru/post/568578/   \n",
       "3   https://habr.com/ru/post/568556/   \n",
       "4   https://habr.com/ru/post/568578/   \n",
       "..                               ...   \n",
       "95  https://habr.com/ru/post/568556/   \n",
       "96  https://habr.com/ru/post/568578/   \n",
       "97  https://habr.com/ru/post/568556/   \n",
       "98  https://habr.com/ru/post/568578/   \n",
       "99  https://habr.com/ru/post/568556/   \n",
       "\n",
       "                                         Текст статьи  \n",
       "0   Я очень долго не воспринимал JavaScript, как я...  \n",
       "1   Было замечательное теплое австрийское утро, и ...  \n",
       "2   Я очень долго не воспринимал JavaScript, как я...  \n",
       "3   Было замечательное теплое австрийское утро, и ...  \n",
       "4   Я очень долго не воспринимал JavaScript, как я...  \n",
       "..                                                ...  \n",
       "95  Было замечательное теплое австрийское утро, и ...  \n",
       "96  Я очень долго не воспринимал JavaScript, как я...  \n",
       "97  Было замечательное теплое австрийское утро, и ...  \n",
       "98  Я очень долго не воспринимал JavaScript, как я...  \n",
       "99  Было замечательное теплое австрийское утро, и ...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc10129",
   "metadata": {},
   "source": [
    "### Задание 2.\n",
    "Обязательная часть\n",
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса Avast Hack Ckeck. Список email-ов задаем переменной в начале кода:\n",
    "EMAIL = [xxx@x.ru, yyy@y.com]\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <дата утечки> - <источник утечки> - <описание утечки>\n",
    "\n",
    "Подсказка: сервис работает при помощи \"скрытого\" API. Внимательно изучите post-запросы.\n",
    "\n",
    "Дополнительная часть (необязательная)\n",
    "Написать скрипт, который будет получать 50 последних постов указанной группы во Вконтакте.\n",
    "Документация к API VK: https://vk.com/dev/methods , вам поможет метод wall.get\n",
    "\n",
    "GROUP = 'netology'  \n",
    "TOKEN = УДАЛЯЙТЕ В ВЕРСИИ ДЛЯ ПРОВЕРКИ, НА GITHUB НЕ ВЫКЛАДЫВАТЬ\n",
    "В итоге должен формироваться датафрейм со столбцами: <дата поста> - <текст поста>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f6c24d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3d2a3558",
   "metadata": {},
   "outputs": [],
   "source": [
    "url0 = 'https://www.avast.com/hackcheck'\n",
    "url = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Edg/91.0.864.70',\n",
    "           'Vaar-Version': '0',\n",
    "           'Content-Type': 'application/json'\n",
    "          }\n",
    "payload = {'email': 'xxx@x.ru'}\n",
    "res = requests.post(url0, params=payload, headers=headers)\n",
    "soup = BeautifulSoup(req.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ee99181d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\r\\n<head><title>405 Not Allowed</title></head>\\r\\n<body>\\r\\n<center><h1>405 Not Allowed</h1></center>\\r\\n<hr><center>nginx</center>\\r\\n</body>\\r\\n</html>\\r\\n<!-- a padding to disable MSIE and Chrome friendly error page -->\\r\\n<!-- a padding to disable MSIE and Chrome friendly error page -->\\r\\n<!-- a padding to disable MSIE and Chrome friendly error page -->\\r\\n<!-- a padding to disable MSIE and Chrome friendly error page -->\\r\\n<!-- a padding to disable MSIE and Chrome friendly error page -->\\r\\n<!-- a padding to disable MSIE and Chrome friendly error page -->\\r\\n'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e53afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
